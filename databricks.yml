bundle:
  name: my-databricks-project

# Define the resources to deploy (Notebooks, SQL files, etc.)
artifacts:
  default:
    type: whl
    build: python setup.py bdist_wheel
    path: .

targets:
  # Dev Environment configuration
  dev:
    default: true
    workspace:
      host: ${DATABRICKS_HOST}
      # This dynamically creates a path like: /Users/user@email.com/.bundle/my-databricks-project/dev
      root_path: /Workspace/Users/rollux2013@gmail.com/databricks-ingestion-platform

resources:
  jobs:
    # Example: A simple job to run a notebook after deployment
    sample_job:
      name: "[${bundle.target}] Sample Notebook Job"
      tasks:
        - task_key: run_notebook
          notebook_task:
            notebook_path: ./notebooks/main_notebook.py
          new_cluster:
            spark_version: "13.3.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1